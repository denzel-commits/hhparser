import os
import time
import json
import requests
from IPython.display import display, clear_output
import tqdm
import tqdm.notebook

import bs4
import pandas as pd
from collections import Counter
from wordcloud import WordCloud
import smtplib
from email.message import EmailMessage
import schedule
from natasha import Doc, MorphVocab, NewsEmbedding, NewsMorphTagger, Segmenter
from sklearn.feature_extraction.text import TfidfVectorizer

from config import EMAIL_CREDENTIALS

# –ö–æ–¥ 1-–≥–æ –¥–Ω—è: –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞

def dump_json(obj, filename):
    """–§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON-—Ñ–∞–π–ª–∞ –Ω–∞ –¥–∏—Å–∫"""
    with open(filename, 'w', encoding='UTF-8') as f:
        json.dump(obj, f, ensure_ascii=False, indent=4)


def get_vacancies(text="python",
                  experience=None, employment=None, schedule=None):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ API HeadHunter"""
    params = {
            "per_page": 100,
            "page": 0,
            "period": 30,
            "text": 'python',
            "experience": experience,
            "employment": employment,
            "schedule": schedule,
        }

    res = requests.get("https://api.hh.ru/vacancies", params=params)
    if not res.ok:
        print('Error:', res)
    vacancies = res.json()["items"]
    pages = res.json()['pages']

    for page in tqdm.trange(1, pages):
        params['page'] = page
        res = requests.get("https://api.hh.ru/vacancies", params=params)
        if res.ok:
            response_json = res.json()
            vacancies.extend(response_json["items"])
        else:
            print(res)

    dump_json(vacancies, 'vacancies.json')

    return vacancies


def get_full_descriptions(vacancies):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–π (—Ä–∞–±–æ—Ç–∞–µ—Ç 20 –º–∏–Ω—É—Ç!)"""
    vacancies_full = []
    for entry in tqdm.tqdm(vacancies):
        vacancy_id = entry['id']
        description = requests.get(f"https://api.hh.ru/vacancies/{vacancy_id}")
        vacancies_full.append(description.json())
        print(description.json())
        time.sleep(0.2) # –≠—Ç–æ—Ç —Ç–∞–π–º–∞—É—Ç –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã hh –Ω–µ –Ω–∞—á–∞–ª –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –∫–∞–ø—á—É
        clear_output()

    dump_json(vacancies_full, 'vacancies_full.json')

    return vacancies_full


def load_from_google_drive(file_id, filename):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —É–∂–µ —Å–∫–∞—á–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤–º–µ—Å—Ç–æ get_full_descriptions"""
    url = f"https://drive.google.com/uc?export=view&id={file_id}"
    res = requests.get(url)
    data = res.json()
    dump_json(data, filename)
    return data


# –ö–æ–¥ 2-–≥–æ –¥–Ω—è: Data Mining - –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤

def preprocess(text):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏:
    '<p><strong>–ö–æ–≥–æ –º—ã –∏—â–µ–º:</strong><br/>Junior Backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞, –≥–æ—Ç–æ–≤–æ–≥–æ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –∫–æ–º–∞–Ω–¥–µ.</p> <p><strong>'
     ‚Üì ‚Üì ‚Üì
    '–∏—Å–∫–∞—Ç—å junior backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ—Ç–æ–≤—ã–π —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ–º–∞–Ω–¥–∞'
    """
    parsed_html = bs4.BeautifulSoup(text)
    text = parsed_html.text # —É–¥–∞–ª–∏–ª–∏ —Ç—ç–≥–∏

    morph_vocab = MorphVocab()
    segmenter = Segmenter()
    embedding = NewsEmbedding()
    morph_tagger = NewsMorphTagger(embedding)
    doc = Doc(text)
    doc.segment(segmenter)
    doc.tag_morph(morph_tagger)

    words = []

    for token in doc.tokens:
        # –ï—Å–ª–∏ —á–∞—Å—Ç—å —Ä–µ—á–∏ –Ω–µ –≤—Ö–æ–¥–∏—Ç –≤ —Å–ø–∏—Å–æ–∫: [–∑–Ω–∞–∫ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏, –ø—Ä–µ–¥–ª–æ–≥, —Å–æ—é–∑, –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ], –≤—ã–ø–æ–ª–Ω—è–µ–º:
        if token.pos not in ['PUNCT', 'ADP', 'CCONJ', 'PRON']:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ '—Å–ø–æ—Å–æ–±–æ–≤' -> '—Å–ø–æ—Å–æ–±'
            token.lemmatize(morph_vocab)
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
            words.append(token.lemma)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª
    # ['–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å', '–ø–∏—Å–∞—Ç—å',  '–∫–æ–¥'] -> '–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å –ø–∏—Å–∞—Ç—å –∫–æ–¥'
    line = ' '.join(words)

    return line


def preprocess_all(document_collection):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –≤–∞–∫–∞–Ω—Å–∏–π. –ù–∞ –≤—Ö–æ–¥ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏.
    –†–∞–±–æ—Ç–∞–µ—Ç –¥–æ –ø–æ–ª—É—á–∞—Å–∞!
    """
    preprocessed = []
    for vacancy in tqdm.tqdm(document_collection):
        preprocessed.append(preprocess(vacancy))

    dump_json(preprocessed, 'preprocessed.json')

    return preprocessed


def get_tf_idf_weights(preprocessed):
    """–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –≤–∏–¥–∞
    '–∏—Å–∫–∞—Ç—å junior backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ—Ç–æ–≤—ã–π —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ–º–∞–Ω–¥–∞'
    –∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ –Ω–∏–º —Å–ª–æ–≤–∞—Ä—å –≤–µ—Å–æ–≤ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤:
    {'–∏—Å–∫–∞—Ç—å': 0.54, 'junior': 0.73, ...}
    """
    vectorizer = TfidfVectorizer(ngram_range=(1, 2))
    #  –û–±—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞ (—Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ–¥–∏—Ä—É—é—â–∏–π —Ç–µ–∫—Å—Ç –≤ –≤–∏–¥–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —á–∏—Å–µ–ª)
    vectorizer.fit(preprocessed)

    tf_idf_words = vectorizer.get_feature_names_out()
    tf_idf_table = vectorizer.transform(preprocessed).toarray()
    weights = tf_idf_table.sum(axis=0)
    indices_order = weights.argsort()[::-1]

    tf_idf_words[indices_order]

    frequencies = dict(zip(tf_idf_words, weights))

    return frequencies

# –ö–æ–¥ 3-–≥–æ –¥–Ω—è: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è email-—Ä–∞—Å—Å—ã–ª–∫–∏ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é

def generate_digest(text="python", experience=None,
                    employment=None, schedule=None,
                    load_presaved=False):
    """–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤ —Å–µ–±–µ –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∏ —Å –Ω—É–ª—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤—Å–µ –Ω—É–∂–Ω—ã–µ
    –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ email —Ñ–∞–π–ª—ã.
    –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä load_presaved=True, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã –∏
    –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è –ø—Ä–µ–¥—Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –¥–∏—Å–∫–∞.
    """
    if load_presaved:
        vacancies_full = load_from_google_drive(
            '1d2NfxfM2n48m5WS6oCCc3rcQ4hdnTQ1v', 'vacancies_full.json')
    else:
        vacancies = get_vacancies(text, experience, employment, schedule)
        print('–ó–∞–≥—Ä—É–∂–µ–Ω–æ', len(vacancies), '–≤–∞–∫–∞–Ω—Å–∏–π')
        vacancies_full = get_full_descriptions(vacancies)

    all_skills = []
    for vacancy in vacancies_full:
        for skill in vacancy['key_skills']:
            all_skills.append(skill['name'])

    frequencies = Counter(all_skills)

    pd.DataFrame(vacancies_full).to_excel('–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π.xlsx')

    print('–¢–æ–ø –Ω–∞–≤—ã–∫–æ–≤ Python-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞:')
    cloud = WordCloud(background_color="white")
    wc_skills = cloud.generate_from_frequencies(frequencies).to_image()
    wc_skills.show()
    wc_skills.save('word_cloud_skills.png')

    vacancies_df = pd.DataFrame(vacancies_full)

    if load_presaved:
        preprocessed = load_from_google_drive(
            '14dcZnE_XvVeCgWCDgJSZiHgYJQm-TYvD', 'preprocessed.json')
    else:
        preprocessed = preprocess_all(vacancies_df['description'])

    frequencies = get_tf_idf_weights(preprocessed)

    print('\n–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π:')
    cloud = WordCloud(background_color="white")
    wc_descriptions = cloud.generate_from_frequencies(frequencies).to_image()
    wc_descriptions.show()
    wc_descriptions.save('word_cloud_descriptions.png')


def send_email(to, sender, password):
    """–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç email"""
    msg = EmailMessage()
    msg['Subject'] = '–¢—Ä–µ–Ω–¥—ã –≤–∞–∫–∞–Ω—Å–∏–π'
    msg['From'] = sender
    msg['To'] = to

    msg.set_content('–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –ø–æ–¥–±–æ—Ä–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π')

    # –í—Å—Ç–∞–≤–ª—è–µ–º HTML
    html_content = '''
    –î–æ–±—Ä—ã–π –¥–µ–Ω—å, –¥–æ—Ä–æ–≥–æ–π –ø–æ–¥–ø–∏—Å—á–∏–∫!<br>
    <br>
    –ü—Ä–∏—Å—ã–ª–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç —Å —Ç—Ä–µ–Ω–¥–∞–º–∏ –≤ –≤–∞–∫–∞–Ω—Å–∏—è—Ö –¥–ª—è Python-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤!<br>

    –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏:<br>
    <img src="cid:0" style="width:200px"><br>
    <br>
    –°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π:<br>

    <img src="cid:1" style="width:200px"><br>
    <br>
    –í–æ –≤–ª–æ–∂–µ–Ω–∏—è—Ö&nbsp;&mdash; –ø–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö.<br>
    <br>
    <br>
    –° —É–≤–∞–∂–µ–Ω–∏–µ–º,<br>
    Python-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ üêç
    '''
    msg.add_alternative(html_content, subtype='html')

    # –°—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –≤ –±–∏–Ω–∞—Ä–Ω–æ–º –≤–∏–¥–µ –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫ –ø–∏—Å—å–º—É

    with open('word_cloud_skills.png', 'rb') as f:
            file_data = f.read()
            msg.get_payload()[-1].add_related(
                file_data, 'word_cloud_skills.png', 'png', cid='<0>')

    with open('word_cloud_descriptions.png', 'rb') as f:
            file_data = f.read()
            msg.get_payload()[-1].add_related(
                file_data, 'word_cloud_descriptions.png', 'png', cid='<1>')

    with open('–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π.xlsx', 'rb') as f:
            file_data = f.read()
            msg.add_attachment(
                file_data, maintype="application",
                subtype="xlsx", filename='–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π.xlsx')

    with smtplib.SMTP_SSL('smtp.yandex.ru', 465) as smtp:
        smtp.login(sender, password)
        smtp.send_message(msg)


# –ü—Ä–æ—á–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ c –ª–æ–≥–∏–Ω–æ–º –∏ –ø–∞—Ä–æ–ª–µ–º –∏–∑ —Ñ–∞–π–ª–∞
# cred_filename = 'credentials.json'
#
# if os.path.exists(cred_filename):
#     with open(cred_filename) as f:
#         credentials = json.load(f)
# else:
#     raise FileNotFoundError(
#         f'–§–∞–π–ª —Å —Ä–µ–∫–≤–∏–∑–∏—Ç–∞–º–∏ –∫ –ø–æ—á—Ç–æ–≤–æ–º—É —è—â–∏–∫—É {cred_filename} –Ω–µ –Ω–∞–π–¥–µ–Ω,\n'
#         '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π –≤—ã—à–µ')

credentials = EMAIL_CREDENTIALS


def job_send_digest():
    """–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏ –æ—Ç–ø—Ä–∞–≤–∫—É –æ—Ç—á–µ—Ç–∞.
    –¢–∞–∫ –∫–∞–∫ –æ–Ω–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é, –æ–Ω–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    """
    # –í–∞—Ä–∏–∞–Ω—Ç –Ω–∞–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Å—É–º–º–∞—Ä–Ω–æ –æ—Ç—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 12 –º–∏–Ω—É—Ç –≤–º–µ—Å—Ç–æ 50)
    generate_digest(
        # –¢—É—Ç –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–Ω–µ –∑–∞–±—É–¥—å—Ç–µ –æ—Ç–∫–ª—é—á–∏—Ç—å load_presaved)
        text="python",
        experience='noExperience',
        employment=['full', 'part'],
        schedule=['fullDay', 'remote'],
        # –ß—Ç–æ–±—ã –∑–∞–≥—Ä—É–∂–∞—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º,
        # –∑–∞–º–µ–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ—á–∫—É –Ω–∞ load_presaved=False,
        # –∞ —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - –Ω–∞ load_presaved=True
        load_presaved=False
        )

    # –ï—Å–ª–∏ —Ö–æ—Ç–∏–º —Ä–∞–∑–æ—Å–ª–∞—Ç—å –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º, –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å
    # —Å–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–æ–≤ –∏ –≤—ã–∑—ã–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é send_email(to, ...) –≤ —Ü–∏–∫–ª–µ
    send_email(credentials['email'],
               credentials['email'],
               credentials['password'])


schedule.clear()
schedule.every(1).day.do(job_send_digest)
schedule.run_all()


# –≠—Ç–æ—Ç —Ü–∏–∫–ª –±—É–¥–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ, –ø–æ–∫–∞ —è—á–µ–π–∫–∞ –Ω–µ –±—É–¥–µ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤—Ä—É—á–Ω—É—é
# (—ç—Ç–æ –≤—ã–∑–æ–≤–µ—Ç KeyboardInterrupt - –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é —Å–ª–µ–¥—É—é—â–µ–π —è—á–µ–π–∫–∏)
while True:
    schedule.run_pending()
    time.sleep(1)